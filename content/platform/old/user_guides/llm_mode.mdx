---
title: LLM Friendly Mode
sidebar_position: 4
description: This guide provides detailed instructions on how to enable LLM mode in the OpenBB Platform.
keywords:
- OpenBB Platform
- LLM mode
- LLM
- ChatGPT
- AI
- Financial Agents
- LLM Compatibility
- Finance AI
- Custom commands
- Python Interface
---

import HeadTitle from '@site/src/components/General/HeadTitle.tsx';

<HeadTitle title="Enable LLM Mode - How-To | OpenBB Platform Docs" />

The OpenBB Platform provides a way to enable the Large Language Model (LLM) mode, which allows you to use LLM frameworks such as [Magentic](https://github.com/jackmpcollins/magentic), [Langchain](https://github.com/langchain-ai/langchain), [Haystack](https://github.com/deepset-ai/haystack), and more.

This guide outlines the steps to enable LLM mode in the OpenBB Platform.

## Enabling LLM Mode

We first start by importing the OpenBB Platform:

```python
from openbb import obb
```

The LLM mode is made possible by setting the system and user preferences to an LLM-compatible mode.

First, we set the user preference:

```python
obb.user.preferences.output_type="llm"
```

This line of code converts the `OBBject` response data results into a format that works good with LLM models. This is based on our own experience with building LLM agents for financial data. You can try other output types such as `dict`, or similar. You can also build your custom output type.

Next, we set the system preferences:

```python
obb.system.python_settings.docstring_sections=['description', 'examples']
```

This system preference trims the docstrings of the commands so that they can fit into the LLM model's context size and also avoid redundant information. The redundant information comes from the information inside the signature of the command that is also written in the docstring.

As our docstrings are modular we can easily choose which section of the docstrings to include. Available docstring sections are the following:

- description
- parameters
- returns
- examples

The next step is to limit the size of the docstrings:

```python
obb.system.python_settings.docstring_max_length=1024
```

We do this to ensure that the docstrings are not too long for the LLM model to process. The LLM model has a limit on the number of tokens it can process at once, and this setting ensures that the docstrings are within that limit.

Finally, we can import `openbb` and rebuild the Python static assets to apply these system changes:

```python
import openbb
openbb.build()
```

Now you have successfully enabled LLM mode in the OpenBB Platform. You can now use LLM frameworks to interact with the OpenBB Platform and build financial agents that can understand and respond to financial data.

For example:

```python
from magentic import prompt_chain, FunctionCall, OpenaiChatModel

@prompt_chain(
    "You are a helpful financial agent that can use function calling to retrieve data.\nUser Query: {query}",
    functions=[obb.equity.price.quote],
    model=OpenaiChatModel(model="gpt-4-turbo-preview")
)
def llm(query: str) -> FunctionCall | str: ...

r = llm(query="What is the current stock price of AAPL?")
r
```
