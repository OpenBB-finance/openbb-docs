"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[9860],{4275:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>l,contentTitle:()=>d,default:()=>p,frontMatter:()=>o,metadata:()=>s,toc:()=>c});const s=JSON.parse('{"id":"workspace/developers/openbb-ai-sdk","title":"OpenBB AI SDK","description":"Build custom agents for OpenBB Workspace using the OpenBB AI SDK helpers and models","source":"@site/content/workspace/developers/openbb-ai-sdk.md","sourceDirName":"workspace/developers","slug":"/workspace/developers/openbb-ai-sdk","permalink":"/workspace/developers/openbb-ai-sdk","draft":false,"unlisted":false,"editUrl":"https://github.com/OpenBB-finance/openbb-docs/edit/main/content/workspace/developers/openbb-ai-sdk.md","tags":[],"version":"current","lastUpdatedBy":"DidierRLopes","lastUpdatedAt":1768857100000,"sidebarPosition":7,"frontMatter":{"title":"OpenBB AI SDK","sidebar_position":7,"description":"Build custom agents for OpenBB Workspace using the OpenBB AI SDK helpers and models","keywords":["OpenBB AI SDK","custom agents","SSE","QueryRequest","widgets","citations","charts","tables"]},"sidebar":"tutorialSidebar","previous":{"title":"Agents Integration","permalink":"/workspace/developers/agents-integration"},"next":{"title":"Share step-by-step reasoning","permalink":"/workspace/developers/ai-features/share-step-by-step-reasoning"}}');var a=t(74848),i=t(28453),r=t(39068);const o={title:"OpenBB AI SDK",sidebar_position:7,description:"Build custom agents for OpenBB Workspace using the OpenBB AI SDK helpers and models",keywords:["OpenBB AI SDK","custom agents","SSE","QueryRequest","widgets","citations","charts","tables"]},d=void 0,l={},c=[{value:"Building Your First Agent",id:"building-your-first-agent",level:2},{value:"Understanding the QueryRequest",id:"understanding-the-queryrequest",level:3},{value:"Core Fields",id:"core-fields",level:4},{value:"Additional Fields",id:"additional-fields",level:4},{value:"Requesting Widget Data",id:"requesting-widget-data",level:2},{value:"Streaming Responses",id:"streaming-responses",level:2},{value:"Text Streaming",id:"text-streaming",level:3},{value:"Reasoning Steps",id:"reasoning-steps",level:3},{value:"Tables",id:"tables",level:3},{value:"Charts",id:"charts",level:3},{value:"Citations &amp; Attribution",id:"citations--attribution",level:2},{value:"Data Format Reference",id:"data-format-reference",level:2},{value:"Complete Agent Example",id:"complete-agent-example",level:2},{value:"Model Reference",id:"model-reference",level:2}];function m(e){const n={a:"a",code:"code",h2:"h2",h3:"h3",h4:"h4",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,i.R)(),...e.components};return(0,a.jsxs)(a.Fragment,{children:[(0,a.jsx)(r.A,{title:"OpenBB AI SDK | OpenBB Workspace Docs"}),"\n",(0,a.jsx)(n.p,{children:"The OpenBB AI SDK simplifies building custom agents for OpenBB Workspace by providing type-safe models and helper functions that handle schema validation for streaming Server-Sent Events (SSE). Instead of manually crafting SSE messages and managing event types, you can use simple Python functions to stream text, show reasoning steps, fetch widget data, and create visualizations."}),"\n",(0,a.jsx)(n.p,{children:"Install the package in your agent backend:"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-bash",children:"pip install openbb-ai\n"})}),"\n",(0,a.jsxs)(n.p,{children:["The code is open source and is ",(0,a.jsx)(n.a,{href:"https://github.com/OpenBB-finance/openbb-ai",children:"available in this repository"}),"."]}),"\n",(0,a.jsx)(n.h2,{id:"building-your-first-agent",children:"Building Your First Agent"}),"\n",(0,a.jsxs)(n.p,{children:["Every agent starts with a query handler that receives a ",(0,a.jsx)(n.code,{children:"QueryRequest"})," object containing everything your agent needs:"]}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:'from openbb_ai.models import QueryRequest\nfrom openbb_ai import message_chunk, reasoning_step\n\nasync def query(request: QueryRequest):\n    """Main entry point for your agent."""\n\n    # Show the user what you\'re doing\n    yield reasoning_step(\n        event_type="INFO",\n        message="Processing your request..."\n    ).model_dump()\n\n    # Access the user\'s latest message\n    last_message = request.messages[-1]\n    if last_message.role == "human":\n        user_query = last_message.content\n\n    # Stream a response from LLM\n    client = openai.AsyncOpenAI()\n    async for event in await client.chat.completions.create(\n        model="gpt-4o",\n        messages=[{"role": "user", "content": user_query}],\n        stream=True,\n    ):\n        if chunk := event.choices[0].delta.content:\n            yield message_chunk(chunk).model_dump()\n'})}),"\n",(0,a.jsx)(n.h3,{id:"understanding-the-queryrequest",children:"Understanding the QueryRequest"}),"\n",(0,a.jsxs)(n.p,{children:["The ",(0,a.jsx)(n.code,{children:"QueryRequest"})," object contains all context your agent needs:"]}),"\n",(0,a.jsx)(n.h4,{id:"core-fields",children:"Core Fields"}),"\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:(0,a.jsx)(n.code,{children:"messages"})})," - Chat conversation history"]}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:'for message in request.messages:\n    if message.role == "human":\n        user_query = message.content\n    elif message.role == "ai":\n        previous_response = message.content\n'})}),"\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:(0,a.jsx)(n.code,{children:"widgets"})})," - Widgets available to your agent"]}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:'# User-selected widgets (requires widget-dashboard-select feature)\nif request.widgets and request.widgets.primary:\n    for widget in request.widgets.primary:\n        print(f"User added: {widget.name}")\n\n# Dashboard widgets (requires widget-dashboard-search feature)\nif request.widgets and request.widgets.secondary:\n    for widget in request.widgets.secondary:\n        print(f"On dashboard: {widget.name}")\n'})}),"\n",(0,a.jsxs)(n.p,{children:["See the ",(0,a.jsx)(n.a,{href:"https://docs.openbb.co/workspace/developers/json-specs/agents-json-reference",children:"agents.json reference"})," for details how to enable the ",(0,a.jsx)(n.code,{children:"widget-dashboard-select"})," and ",(0,a.jsx)(n.code,{children:"widget-dashboard-search"})," features."]}),"\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:(0,a.jsx)(n.code,{children:"workspace_state"})})," - Current workspace context"]}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:'if request.workspace_state and request.workspace_state.current_dashboard_info:\n    dashboard = request.workspace_state.current_dashboard_info\n    print(f"Active tab: {dashboard.current_tab_id}")\n'})}),"\n",(0,a.jsx)(n.h4,{id:"additional-fields",children:"Additional Fields"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:(0,a.jsx)(n.code,{children:"tools"})})," - MCP tools available for execution"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:(0,a.jsx)(n.code,{children:"urls"})})," - URLs shared in chat (max 4)"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:(0,a.jsx)(n.code,{children:"timezone"})}),' - User\'s browser timezone (e.g., "America/New_York")']}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:(0,a.jsx)(n.code,{children:"api_keys"})})," - Custom API keys from user"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:(0,a.jsx)(n.code,{children:"workspace_options"})})," - Enabled feature flags (including custom ones)"]}),"\n"]}),"\n",(0,a.jsx)(n.h2,{id:"requesting-widget-data",children:"Requesting Widget Data"}),"\n",(0,a.jsxs)(n.p,{children:["Both ",(0,a.jsx)(n.code,{children:"get_widget_data"})," and MCP tool calls are executed client-side. When you yield these function calls, the following sequence occurs:"]}),"\n",(0,a.jsxs)(n.ol,{children:["\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Agent sends tool call"})," - Your agent yields the function call (widget request or MCP tool)"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Connection closes"})," - The SSE stream is terminated, breaking the connection"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Frontend executes"})," - Workspace executes the requested tool call/widget request in the browser"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"New request initiated"})," - Frontend sends a new POST ",(0,a.jsx)(n.code,{children:"/query"})," request with the tool results"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Agent resumes"})," - Your agent receives a new ",(0,a.jsx)(n.code,{children:"QueryRequest"})," with the execution results as a ",(0,a.jsx)(n.code,{children:"tool"})," message"]}),"\n"]}),"\n",(0,a.jsxs)(n.p,{children:["This isn't a simple \"pause\" - it's a complete request/response cycle. Your agent must be stateless and handle being called multiple times. For a detailed sequence diagram of this flow, see the ",(0,a.jsx)(n.a,{href:"https://github.com/OpenBB-finance/openbb-ai#readme",children:"OpenBB AI SDK repository"}),"."]}),"\n",(0,a.jsx)(n.p,{children:"Example:"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:'from openbb_ai import WidgetRequest, message_chunk, reasoning_step, get_widget_data\nfrom openbb_ai.models import QueryRequest, ClientFunctionCallError, DataContent\n\nasync def query(request: QueryRequest):\n    last_message = request.messages[-1]\n    \n    # Check if this is a tool response first\n    is_tool_response = (\n        last_message\n        and hasattr(last_message, "role")\n        and last_message.role == "tool"\n        and hasattr(last_message, "data")\n        and last_message.data\n    )\n    \n    if is_tool_response:\n        # Process widget data (Step 3)\n        yield reasoning_step(event_type="INFO", message="Processing data...").model_dump()\n        \n        for item in last_message.data:\n            if isinstance(item, DataContent):\n                # Process the data and respond\n                yield message_chunk("Here\'s what I found in the data...").model_dump()\n        return\n    \n    # Check for orchestration requests\n    orchestration_requested = (\n        last_message.role == "ai" and last_message.agent_id == "openbb-copilot"\n    )\n    \n    # Phase 1: Check if we need to fetch primary data (added to context)\n    if ((last_message.role == "human" or orchestration_requested) \n        and request.widgets and request.widgets.primary):\n        widget_requests = [\n            WidgetRequest(\n                widget=widget,\n                input_arguments={\n                    param.name: param.current_value for param in widget.params\n                }\n            )\n            for widget in request.widgets.primary\n        ]\n        \n        yield reasoning_step(event_type="INFO", message="Fetching widget data...").model_dump()\n        yield get_widget_data(widget_requests).model_dump()\n        return  # EXIT AND WAIT\n    \n    # Phase 2: Process fetched data\n    if hasattr(last_message, \'data\'):\n        yield reasoning_step(event_type="INFO", message="Processing data...").model_dump()\n        \n        for item in last_message.data:\n            if isinstance(item, DataContent):\n                # Process the data and respond\n                yield message_chunk("Here\'s what I found in the data...").model_dump()\n'})}),"\n",(0,a.jsxs)(n.p,{children:["Use ",(0,a.jsx)(n.code,{children:"request.widgets.primary"})," for widgets the user selected in chat and ",(0,a.jsx)(n.code,{children:"request.widgets.secondary"})," for widgets already on the dashboard (when the dashboard features are enabled). The SDK formats the tool call for you. Your only responsibility is to pause after yielding ",(0,a.jsx)(n.code,{children:"get_widget_data"})," and handle the callback that arrives as a ",(0,a.jsx)(n.code,{children:"tool"})," message."]}),"\n",(0,a.jsx)(n.h2,{id:"streaming-responses",children:"Streaming Responses"}),"\n",(0,a.jsx)(n.p,{children:"The SDK provides several ways to stream content back to users:"}),"\n",(0,a.jsx)(n.h3,{id:"text-streaming",children:"Text Streaming"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:'from openbb_ai import message_chunk\n\n# Stream from LLM response\nasync for event in await client.chat.completions.create(\n    model="gpt-4o",\n    messages=messages,\n    stream=True,\n):\n    if chunk := event.choices[0].delta.content:\n        yield message_chunk(chunk).model_dump()\n'})}),"\n",(0,a.jsx)(n.h3,{id:"reasoning-steps",children:"Reasoning Steps"}),"\n",(0,a.jsx)(n.p,{children:"Show users what your agent is thinking:"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:'from openbb_ai import reasoning_step\n\n# Different event types for different states\nyield reasoning_step(event_type="INFO", message="Analyzing market data").model_dump()\nyield reasoning_step(event_type="SUCCESS", message="Found 50 matching results").model_dump()\nyield reasoning_step(event_type="WARNING", message="Some data may be delayed").model_dump()\nyield reasoning_step(event_type="ERROR", message="Failed to fetch real-time data").model_dump()\n\n# Include additional details\nyield reasoning_step(\n    event_type="SUCCESS",\n    message="Data retrieved",\n    details={"records": 1000, "timeframe": "1Y"}\n).model_dump()\n'})}),"\n",(0,a.jsx)(n.h3,{id:"tables",children:"Tables"}),"\n",(0,a.jsx)(n.p,{children:"Create interactive data tables:"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:'from openbb_ai import table\n\nyield table(\n    data=[\n        {"Symbol": "AAPL", "Price": 150.25, "Change": "+2.5%"},\n        {"Symbol": "GOOGL", "Price": 2800.00, "Change": "-0.3%"},\n        {"Symbol": "MSFT", "Price": 380.50, "Change": "+1.2%"}\n    ],\n    name="Stock Prices",\n    description="Current market prices"\n).model_dump()\n'})}),"\n",(0,a.jsx)(n.h3,{id:"charts",children:"Charts"}),"\n",(0,a.jsx)(n.p,{children:"Create visualizations with different chart types:"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:'from openbb_ai import chart\n\n# Line chart for time series\nyield chart(\n    type="line",\n    data=[\n        {"date": "2024-01-01", "price": 150.25},\n        {"date": "2024-01-02", "price": 151.30},\n        {"date": "2024-01-03", "price": 148.90}\n    ],\n    x_key="date",\n    y_keys=["price"],\n    name="Price History",\n    description="Stock price over time"\n).model_dump()\n\n# Bar chart for comparisons\nyield chart(\n    type="bar",\n    data=[\n        {"symbol": "AAPL", "volume": 50000000},\n        {"symbol": "GOOGL", "volume": 25000000},\n        {"symbol": "MSFT", "volume": 40000000}\n    ],\n    x_key="symbol",\n    y_keys=["volume"],\n    name="Trading Volume",\n    description="Volume by symbol"\n).model_dump()\n'})}),"\n",(0,a.jsxs)(n.p,{children:["Supported chart types: ",(0,a.jsx)(n.code,{children:"line"}),", ",(0,a.jsx)(n.code,{children:"bar"}),", ",(0,a.jsx)(n.code,{children:"scatter"}),", ",(0,a.jsx)(n.code,{children:"pie"}),", ",(0,a.jsx)(n.code,{children:"donut"})]}),"\n",(0,a.jsx)(n.h2,{id:"citations--attribution",children:"Citations & Attribution"}),"\n",(0,a.jsx)(n.p,{children:"Always cite your data sources to maintain transparency:"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:'from openbb_ai import cite, citations\n\n# Create citations for widgets you used\ncitation_list = []\n\nfor widget in request.widgets.primary:\n    citation_list.append(\n        cite(\n            widget=widget,\n            input_arguments={\n                param.name: param.current_value\n                for param in widget.params\n            },\n            extra_details={"timeframe": "1D"}\n        )\n    )\n\n# Send all citations at once\nyield citations(citation_list).model_dump()\n'})}),"\n",(0,a.jsx)(n.h2,{id:"data-format-reference",children:"Data Format Reference"}),"\n",(0,a.jsx)(n.p,{children:"Widget data can come in various formats:"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:"from openbb_ai.models import (\n    PdfDataFormat,\n    ImageDataFormat,\n    SpreadsheetDataFormat,\n    RawObjectDataFormat,\n    SingleDataContent,\n    SingleFileReference\n)\n\nasync def handle_widget_data(data: list[DataContent | DataFileReferences]):\n    for result in data:\n        for item in result.items:\n            if isinstance(item.data_format, PdfDataFormat):\n                # Handle PDF - use pdfplumber or similar\n                if isinstance(item, SingleDataContent):\n                    pdf_bytes = base64.b64decode(item.content)\n                elif isinstance(item, SingleFileReference):\n                    pdf_url = item.url\n\n            elif isinstance(item.data_format, SpreadsheetDataFormat):\n                # Handle Excel/CSV - use pandas\n                df = pd.read_json(item.content)\n\n            elif isinstance(item.data_format, ImageDataFormat):\n                # Handle images - may need OCR\n                image_data = base64.b64decode(item.content)\n\n            else:  # RawObjectDataFormat\n                # Handle JSON/dict data\n                data = json.loads(item.content)\n"})}),"\n",(0,a.jsx)(n.h2,{id:"complete-agent-example",children:"Complete Agent Example"}),"\n",(0,a.jsx)(n.p,{children:"Here's a minimal but complete agent that demonstrates the key concepts:"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:'from openbb_ai import WidgetRequest, message_chunk, reasoning_step, cite, citations, table, get_widget_data\nfrom openbb_ai.models import QueryRequest, DataContent, ClientFunctionCallError\nimport json\n\nasync def query(request: QueryRequest):\n    """Complete agent implementation with widget data flow."""\n\n    last_message = request.messages[-1]\n\n    # Check for orchestration requests\n    orchestration_requested = (\n        last_message.role == "ai" and last_message.agent_id == "openbb-copilot"\n    )\n\n    # Phase 1: Fetch widget data if needed\n    if ((last_message.role == "human" or orchestration_requested)\n        and request.widgets and request.widgets.primary):\n        widget_requests = [\n            WidgetRequest(\n                widget=widget,\n                input_arguments={\n                    param.name: param.current_value for param in widget.params\n                }\n            )\n            for widget in request.widgets.primary\n        ]\n\n        yield reasoning_step(\n            event_type="INFO",\n            message="Fetching market data..."\n        ).model_dump()\n\n        yield get_widget_data(widget_requests).model_dump()\n        return  # Exit and wait for callback\n\n    # Phase 2: Process widget data\n    if hasattr(last_message, \'data\'):\n        yield reasoning_step(\n            event_type="INFO",\n            message="Analyzing data..."\n        ).model_dump()\n\n        # Process the data\n        results = []\n        for item in last_message.data:\n            if isinstance(item, ClientFunctionCallError):\n                yield reasoning_step(\n                    event_type="ERROR",\n                    message=f"Failed: {item.content}"\n                ).model_dump()\n                continue\n\n            if isinstance(item, DataContent):\n                for data_item in item.items:\n                    data = json.loads(data_item.content)\n                    results.append(data)\n\n        # Stream response from LLM\n        yield message_chunk("Based on the market data analysis:\\n").model_dump()\n\n        # Continue with LLM streaming\n        client = openai.AsyncOpenAI()\n        async for event in await client.chat.completions.create(\n            model="gpt-4o",\n            messages=openai_messages,\n            stream=True,\n        ):\n            if chunk := event.choices[0].delta.content:\n                yield message_chunk(chunk).model_dump()\n\n        # Show data table\n        if results:\n            yield table(\n                data=results[:5],  # Show top 5\n                name="Market Summary",\n                description="Key metrics"\n            ).model_dump()\n\n        # Add citations\n        citation_list = [\n            cite(widget=widget, input_arguments={\n                param.name: param.current_value for param in widget.params\n            })\n            for widget in request.widgets.primary\n        ]\n        yield citations(citation_list).model_dump()\n\n        yield reasoning_step(\n            event_type="SUCCESS",\n            message="Analysis complete"\n        ).model_dump()\n\n    # Phase 3: Handle regular chat without widgets\n    else:\n        yield message_chunk("Please add some widgets to analyze market data.").model_dump()\n'})}),"\n",(0,a.jsx)(n.h2,{id:"model-reference",children:"Model Reference"}),"\n",(0,a.jsxs)(n.p,{children:["To see the available models check ",(0,a.jsx)(n.a,{href:"https://github.com/OpenBB-finance/openbb-ai/blob/main/openbb_ai/models.py",children:"https://github.com/OpenBB-finance/openbb-ai/blob/main/openbb_ai/models.py"}),"."]})]})}function p(e={}){const{wrapper:n}={...(0,i.R)(),...e.components};return n?(0,a.jsx)(n,{...e,children:(0,a.jsx)(m,{...e})}):m(e)}},28453:(e,n,t)=>{t.d(n,{R:()=>r,x:()=>o});var s=t(96540);const a={},i=s.createContext(a);function r(e){const n=s.useContext(i);return s.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function o(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(a):e.components||a:r(e.components),s.createElement(i.Provider,{value:n},e.children)}},39068:(e,n,t)=>{t.d(n,{A:()=>i});t(96540);var s=t(27143),a=t(74848);function i(e){let{title:n}=e;return(0,a.jsx)(s.A,{children:(0,a.jsx)("title",{children:n})})}}}]);