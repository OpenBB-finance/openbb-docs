"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[46988],{28453:(e,t,s)=>{s.d(t,{R:()=>i,x:()=>d});var n=s(96540);const a={},r=n.createContext(a);function i(e){const t=n.useContext(r);return n.useMemo((function(){return"function"==typeof e?e(t):{...t,...e}}),[t,e])}function d(e){let t;return t=e.disableParentContext?"function"==typeof e.components?e.components(a):e.components||a:i(e.components),n.createElement(r.Provider,{value:t},e.children)}},39068:(e,t,s)=>{s.d(t,{A:()=>r});s(96540);var n=s(27143),a=s(74848);function r(e){let{title:t}=e;return(0,a.jsx)(n.A,{children:(0,a.jsx)("title",{children:t})})}},91795:(e,t,s)=>{s.r(t),s.d(t,{assets:()=>c,contentTitle:()=>o,default:()=>p,frontMatter:()=>d,metadata:()=>n,toc:()=>l});const n=JSON.parse('{"id":"workspace/developers/ai-features/parse-widget-data","title":"Parse widget data","description":"Retrieve data from selected widgets and pass it as raw context to your LLM","source":"@site/content/workspace/developers/ai-features/parse-widget-data.md","sourceDirName":"workspace/developers/ai-features","slug":"/workspace/developers/ai-features/parse-widget-data","permalink":"/workspace/developers/ai-features/parse-widget-data","draft":false,"unlisted":false,"editUrl":"https://github.com/OpenBB-finance/openbb-docs/edit/main/content/workspace/developers/ai-features/parse-widget-data.md","tags":[],"version":"current","lastUpdatedBy":"DidierRLopes","lastUpdatedAt":1764165530000,"sidebarPosition":2,"frontMatter":{"title":"Parse widget data","sidebar_position":2,"description":"Retrieve data from selected widgets and pass it as raw context to your LLM","keywords":["widgets","get_widget_data","WidgetRequest","SSE","OpenAI"]},"sidebar":"tutorialSidebar","previous":{"title":"Share step-by-step reasoning","permalink":"/workspace/developers/ai-features/share-step-by-step-reasoning"},"next":{"title":"Parse PDF context","permalink":"/workspace/developers/ai-features/parse-pdf-context"}}');var a=s(74848),r=s(28453),i=s(39068);const d={title:"Parse widget data",sidebar_position:2,description:"Retrieve data from selected widgets and pass it as raw context to your LLM",keywords:["widgets","get_widget_data","WidgetRequest","SSE","OpenAI"]},o=void 0,c={},l=[{value:"Architecture",id:"architecture",level:2},{value:"Query flow",id:"query-flow",level:3},{value:"OpenBB AI SDK",id:"openbb-ai-sdk",level:3},{value:"Core logic",id:"core-logic",level:2},{value:"Dashboard widgets vs explicit context",id:"dashboard-widgets-vs-explicit-context",level:2}];function u(e){const t={a:"a",code:"code",h2:"h2",h3:"h3",li:"li",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,r.R)(),...e.components};return(0,a.jsxs)(a.Fragment,{children:[(0,a.jsx)(i.A,{title:"AI Features \u2014 Parse widget data | OpenBB Workspace Docs"}),"\n",(0,a.jsxs)(t.p,{children:["Retrieve data for user\u2011selected widgets and pass it to your model. Enable ",(0,a.jsx)(t.code,{children:"widget-dashboard-select"})," and call ",(0,a.jsx)(t.code,{children:"get_widget_data"})," when the latest user message arrives."]}),"\n",(0,a.jsxs)(t.p,{children:["Reference implementation in ",(0,a.jsx)(t.a,{href:"https://github.com/OpenBB-finance/agents-for-openbb/tree/main/30-vanilla-agent-raw-widget-data/vanilla_agent_raw_context/main.py",children:"this GitHub repository"}),"."]}),"\n",(0,a.jsx)("img",{className:"pro-border-gradient",width:"800",alt:"Raw reply without context",src:"https://openbb-cms.directus.app/assets/7bbbc4c9-7cd2-4bb0-9ad9-641588cf541e.png"}),"\n",(0,a.jsx)(t.h2,{id:"architecture",children:"Architecture"}),"\n",(0,a.jsx)(t.p,{children:"This pattern uses a minimal FastAPI backend with two endpoints and OpenBB AI SDK helpers to retrieve widget data and stream results."}),"\n",(0,a.jsxs)(t.p,{children:[(0,a.jsx)(t.code,{children:"agents.json"})," configuration with ",(0,a.jsx)(t.code,{children:"widget-dashboard-select"})," feature enabled:"]}),"\n",(0,a.jsx)(t.pre,{children:(0,a.jsx)(t.code,{className:"language-python",children:'return JSONResponse(content={\n  "vanilla_agent_raw_context": {\n    "endpoints": {"query": "http://localhost:7777/v1/query"},\n    "features": {\n      "widget-dashboard-select": True,\n      "widget-dashboard-search": False,\n    },\n  }\n})\n'})}),"\n",(0,a.jsx)(t.h3,{id:"query-flow",children:"Query flow"}),"\n",(0,a.jsxs)(t.ul,{children:["\n",(0,a.jsxs)(t.li,{children:["Check if latest message is human with ",(0,a.jsx)(t.code,{children:"widgets.primary"})," populated"]}),"\n",(0,a.jsxs)(t.li,{children:["Build ",(0,a.jsx)(t.code,{children:"WidgetRequest"})," objects with current parameter values"]}),"\n",(0,a.jsxs)(t.li,{children:["Early exit: yield ",(0,a.jsx)(t.code,{children:"get_widget_data()"})," SSE immediately for UI to execute"]}),"\n",(0,a.jsxs)(t.li,{children:["On subsequent request with tool results:","\n",(0,a.jsxs)(t.ul,{children:["\n",(0,a.jsxs)(t.li,{children:["Parse ",(0,a.jsx)(t.code,{children:"DataContent"})," items from tool message"]}),"\n",(0,a.jsx)(t.li,{children:"Extract and format widget data into context string"}),"\n",(0,a.jsx)(t.li,{children:"Append context to user messages for LLM processing"}),"\n",(0,a.jsxs)(t.li,{children:["Stream LLM response with ",(0,a.jsx)(t.code,{children:"message_chunk()"})]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsx)(t.h3,{id:"openbb-ai-sdk",children:"OpenBB AI SDK"}),"\n",(0,a.jsxs)(t.ul,{children:["\n",(0,a.jsxs)(t.li,{children:[(0,a.jsx)(t.code,{children:"get_widget_data(widget_requests)"}),": Creates ",(0,a.jsx)(t.code,{children:"FunctionCallSSE"})," for widget data retrieval"]}),"\n",(0,a.jsxs)(t.li,{children:[(0,a.jsx)(t.code,{children:"WidgetRequest(widget, input_arguments)"}),": Specifies widget and parameter values"]}),"\n",(0,a.jsxs)(t.li,{children:[(0,a.jsx)(t.code,{children:"Widget"}),": Contains widget metadata (uuid, name, type, params)"]}),"\n",(0,a.jsxs)(t.li,{children:[(0,a.jsx)(t.code,{children:"WidgetParam"}),": Individual parameter with name, type, current_value"]}),"\n",(0,a.jsxs)(t.li,{children:[(0,a.jsx)(t.code,{children:"DataContent"}),": Container for widget response data"]}),"\n",(0,a.jsxs)(t.li,{children:[(0,a.jsx)(t.code,{children:"message_chunk(text)"}),": Creates ",(0,a.jsx)(t.code,{children:"MessageChunkSSE"})," for streaming text"]}),"\n"]}),"\n",(0,a.jsx)(t.h2,{id:"core-logic",children:"Core logic"}),"\n",(0,a.jsx)(t.pre,{children:(0,a.jsx)(t.code,{className:"language-python",children:'from openbb_ai import get_widget_data, WidgetRequest, message_chunk\n\n@app.post("/v1/query")\nasync def query(request: QueryRequest) -> EventSourceResponse:\n    if (\n        request.messages[-1].role == "human"\n        and request.widgets\n        and request.widgets.primary\n    ):\n        widget_requests = [\n            WidgetRequest(\n                widget=w,\n                input_arguments={p.name: p.current_value for p in w.params},\n            )\n            for w in request.widgets.primary\n        ]\n\n        async def retrieve_widget_data():\n            # Function-call SSE that Workspace interprets and executes\n            yield get_widget_data(widget_requests).model_dump()\n\n        return EventSourceResponse(retrieve_widget_data(), media_type="text/event-stream")\n\n    # Process tool message with widget data\n    openai_messages = [\n        ChatCompletionSystemMessageParam(\n            role="system",\n            content="You are a helpful financial assistant."\n        )\n    ]\n\n    context_str = ""\n    for message in request.messages:\n        if message.role == "human":\n            openai_messages.append(\n                ChatCompletionUserMessageParam(role="user", content=message.content)\n            )\n        elif message.role == "tool":\n            # Extract widget data from latest tool result\n            for data_content in message.data:\n                for item in data_content.items:\n                    context_str += str(item.content) + "\\n"\n\n    # Append context to last user message\n    if context_str and openai_messages:\n        openai_messages[-1]["content"] += "\\n\\nContext:\\n" + context_str\n\n    async def execution_loop():\n        async for event in await client.chat.completions.create(\n            model="gpt-4o",\n            messages=openai_messages,\n            stream=True\n        ):\n            if chunk := event.choices[0].delta.content:\n                yield message_chunk(chunk).model_dump()\n\n    return EventSourceResponse(execution_loop(), media_type="text/event-stream")\n'})}),"\n",(0,a.jsx)(t.h2,{id:"dashboard-widgets-vs-explicit-context",children:"Dashboard widgets vs explicit context"}),"\n",(0,a.jsxs)(t.p,{children:["The example above uses ",(0,a.jsx)(t.code,{children:"request.widgets.primary"})," which contains widgets explicitly selected by the user. If you want to access all widgets available on the current dashboard instead, you can use ",(0,a.jsx)(t.code,{children:"request.widgets.secondary"}),":"]}),"\n",(0,a.jsx)(t.pre,{children:(0,a.jsx)(t.code,{className:"language-python",children:'# Access dashboard widgets instead of explicit context\nif (\n    request.messages[-1].role == "human"\n    and request.widgets\n    and request.widgets.secondary  # Dashboard widgets\n):\n    widget_requests = [\n        WidgetRequest(\n            widget=w,\n            input_arguments={p.name: p.current_value for p in w.params},\n        )\n        for w in request.widgets.secondary  # Use secondary instead of primary\n    ]\n'})}),"\n",(0,a.jsxs)(t.p,{children:[(0,a.jsx)(t.strong,{children:"Important"}),": To access dashboard widgets, you must enable the ",(0,a.jsx)(t.code,{children:"widget-dashboard-search"})," feature in your ",(0,a.jsx)(t.code,{children:"agents.json"}),":"]}),"\n",(0,a.jsx)(t.pre,{children:(0,a.jsx)(t.code,{className:"language-python",children:'"features": {\n    ...\n    "widget-dashboard-search": True,   # Dashboard widgets\n}\n'})}),"\n",(0,a.jsx)(t.p,{children:"This gives your agent broader context about the user's dashboard setup and available data sources, rather than just the widgets they've explicitly selected."})]})}function p(e={}){const{wrapper:t}={...(0,r.R)(),...e.components};return t?(0,a.jsx)(t,{...e,children:(0,a.jsx)(u,{...e})}):u(e)}}}]);